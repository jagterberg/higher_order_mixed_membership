countries[countries=="Netherlands Antilles"] <- "Netherlands"
countries[countries == "Syrian Arab Republic" ] <- "Syria"
countries
# we determine the pure nodes for each mode
pure_nodes1 <-countries[clusts[[2]][[2]]]
pure_nodes2 <- countries[clusts[[2]][[3]]]
#they are the same as we only used undirected relationships
##########################
# Create Figure 1
##########################
world <- map_data("world")
world <- fortify(world, region="id")
myPalette <- colorRampPalette(rev(brewer.pal(11, "Spectral")))
sc <- scale_fill_gradientn(colours = myPalette(100), limits=c(0, 1))
#function below takes in a pure node and plots the intensity of membership
# for that pure node for each country based on the palette above.
# note: if multiple=TRUE then we can combine pure nodes.  this is needed for Figure
# 7 in the paper, where we plot both USA and Canada together.
plot_pure_node <- function(node,multiple=FALSE,legend=FALSE) {
if(multiple) {
tit <- "Pure Node: "
ddf$value <- 0
for ( i in c(1:length(node))) {
eval(parse(text=paste0("value <- ddf$",node[i])))
ddf$value <- value + ddf$value
if (i > 1) {
tit <- paste(tit, "and")
}
tit <- paste(tit,node[i])
}
} else {
eval(parse(text=paste0("ddf$value <- ddf$",node)))
tit <- paste0("Pure Node: ",node)
}
world %>%
merge(ddf, by.x = "region", by.y = "country", all.x = T) %>%
arrange(group, order) %>%
ggplot(aes(x = long, y = lat, group = group, fill = value)) +
geom_polygon(color = "white", size = 0.2) +
sc +
scale_y_continuous(limits=c(-60,90))+
theme_minimal() +
theme(axis.text = element_blank(),
axis.title = element_blank(),
panel.grid = element_blank()) +
ggtitle(tit)
}
# we now plot the different pure node memberships.  First we format the data:
dat <- round(as.data.frame(clusts[[1]][[2]]),4)
var <-pure_nodes1
var
names(dat) <- var #label the communities by pure node
dat$country <- countries
ddf <- dat
#preliminary plots:
plot_pure_node(var[1])
#USA and Canada combined:
plot_pure_node(c(var[1],var[3]),TRUE)
plot_pure_node(var[2])
plot_pure_node(var[3])
plot_pure_node(var[4])
# We now produce a plot for each pure node, which we combine manually in the paper
png("../output/Pure_node_USA.png",units='in',width=8,height=5,res=300)
plot_pure_node(var[1])
dev.off()
png("../output/Pure_node_Japan.png",units='in',width=8,height=5,res=300)
plot_pure_node(var[2])
dev.off()
png("../output/Pure_node_Canada.png",units='in',width=8,height=5,res=300)
plot_pure_node(var[3])
dev.off()
png("../output/Pure_node_Germany.png",units='in',width=8,height=5,res=300)
plot_pure_node(var[4])
dev.off()
# we also produce figure 7:
png("../output/Pure_node_USACanada.png",units='in',width=8,height=5,res=300)
plot_pure_node(c(var[1],var[3]),TRUE)
dev.off()
################################
#' This script creates the simulation figure (Figure 3) assuming that the simulations
#' have been run.
#################################
library(reshape)
#first format the data from each simulation
hetamt1 <- 1
load("../output/sim1_9-19.Rdata")
ps <- seq(100,500,50)
sigmas <- seq(1,100,5)
result1 <- matrix(0,length(sigmas),length(ps))
rownames(result1) <- sigmas
colnames(result1) <- as.character(ps)
for (i in c(1:length(ps)) ) {
result1[,i] <- as.numeric(rowMeans(finalres_uniform[[i]]))
}
result1
load("../output/sim2_9-19.Rdata")
result2 <- matrix(0,length(sigmas),length(ps))
rownames(result2) <- sigmas
colnames(result2) <- as.character(ps)
for (i in c(1:length(ps)) ) {
result2[,i] <- as.numeric(rowMeans(finalres_het1[[i]]))
}
result2
load("../output/sim3_9-19.Rdata")
result3 <- matrix(0,length(sigmas),length(ps))
rownames(result3) <- sigmas
colnames(result3) <- as.character(ps)
for (i in c(1:length(ps)) ) {
result3[,i] <- as.numeric(rowMeans(finalres_het2[[i]]))
}
result3
load("../output/sim4_9-19.Rdata")
result4 <- matrix(0,length(sigmas),length(ps))
rownames(result4) <- sigmas
colnames(result4) <-as.character(ps)
for (i in c(1:length(ps)) ) {
result4[,i] <- as.numeric(rowMeans(finalres_het3[[i]]))
}
result4
#now combine all data into a dataframe in order to plot it
resultattempt <- data.frame(rbind(result1,result2,result3,result4))
resultattempt$sigmaval <- as.numeric(rep(rownames(result1),4))
resultattempt$hetamt <- as.factor(c(rep(1,length(sigmas)),rep(.75,length(sigmas)),
rep(.5,length(sigmas)),rep(.25,length(sigmas))))
results <- melt(resultattempt,id=c("hetamt","sigmaval"))
results$pfactor <- sub('X','',results$variable)
results$p <- as.numeric(sub('X','',results$variable))
#plot 1: a curve as sigma increases (figure 3, LHS)
library(ggplot2)
g <- ggplot(data=results[which(results$hetamt == "1"),],aes(x=sigmaval,y=value,color=as.factor(p)))
g1 <- g + geom_point() + geom_line(linetype="dashed") + xlab("sigma_max") +
ylab("2 -> infty error") +  guides(color=guide_legend(title="p")) +
ggtitle("2 -> infty error, averaged over 10 runs")
# next a plot of relative error as a function of p (RHS)
library(dplyr)
results$relativeerror <- results$value/results$sigmaval
results <-tibble(results)
results_new <- results
results_new$value <- NULL
results_new$sigmaval <- NULL
results_new <- results_new %>% group_by(pfactor,hetamt) %>%
mutate(meanerror = mean(relativeerror))
g <- ggplot(data=results_new,aes(x=p,y=meanerror,color=hetamt))
g2 <- g + geom_point() + geom_line(linetype="dashed") +
ylab("Mean relative 2-> infty error")
#save the LHS and RHS of each figure
png("../output/sigma_error.png",units='in',width=5,height=5,res=300)
g1
dev.off()
png("../output/p_relative_error.png",units='in',width=5,height=5,res=300)
g2
dev.off()
############################
#' This script contains the code to analyze the global flight dataset from the
#' supplementary material.  In particular, it contains the code to produce figure 3.
##########################
source("misc.R")
source("HOOI.R")
source("membership_estimation.R")
library(reshape)
library(dplyr)
##############################
# Process data and obtain memberships
################################
load('../data/flight_route.RData')
air_tensor <- as.tensor(air_tensor)
rs <- c(5,5,5)
Uhats <- HOOI_dd(air_tensor,r=rs,niter=20)
clusts <- SPAMM(uhats = Uhats,threshold=T,tval=10^(-10))
round(clusts[[1]][[2]],3)
round(clusts[[1]][[1]],3)
# obtain the pure nodes
purelines <- pick_linename[clusts[[2]][[1]]]
pureports <- pick_portname[clusts[[2]][[2]]]
# look at pure nodes
select_airl_info[select_airl_info$V4 %in% purelines,]$V2
# associate the row indices to their names
rownames(clusts[[1]][[1]]) <- select_airl_info[order(select_airl_info$V4),]$V2
#save the memberships for the airlines according to the pure nodes
# (note: hardcoded because of ordering)
purelines
cols <- c("united","US airways","british airways","delta","air china")
colnames(clusts[[1]][[1]]) <- cols
# final airline memberships:
round(clusts[[1]][[1]],3)
#look at just chinese airlines and american airlines separately
america_airport_membs <- round(clusts[[1]][[2]][which(rownames(clusts[[1]][[2]]) %in%
select_airport_info[select_airport_info$V4 == 'United States',]$V2), ],3)
china_airport_membs <-  round(clusts[[1]][[2]][which(rownames(clusts[[1]][[2]]) %in%
select_airport_info[select_airport_info$V4 == 'China',]$V2), ],3)
# first find the row names for the airports
rownames(clusts[[1]][[2]]) <- select_airport_info[order(select_airport_info$V5),]$V2
#examine pure nodes:
select_airport_info[select_airport_info$V5 %in% pureports,]$V2
# we now save the column names according to the pure node:
#note: hardcoded due to ordering
pureports
rowz <- c("london","atlanta","chicago","Beijing","Newark")
colnames(clusts[[1]][[2]]) <- rowz
# view the modified data
round(clusts[[1]][[2]],3)
# look at US and China memberships
china_airline_membs <- round(clusts[[1]][[1]][which(rownames(clusts[[1]][[1]]) %in%
select_airl_info[select_airl_info$V7 == 'China',]$V2), ],3)
america_airline_membs <- round(clusts[[1]][[1]][which(rownames(clusts[[1]][[1]]) %in%
select_airl_info[select_airl_info$V7 == 'United States',]$V2), ],3)
# make a data frame from the memberships
dat <- as.data.frame(clusts[[1]][[2]])
dat$country <- "Other"
dat$country[which(rownames(clusts[[1]][[2]]) %in%
select_airport_info[select_airport_info$V4
== 'United States',]$V2)] <- "USA"
dat$country[which(rownames(clusts[[1]][[2]]) %in%
select_airport_info[select_airport_info$V4
== "China",]$V2)]  <- "China"
dat$airport <- rownames(clusts[[1]][[2]])
dat_new <- melt(data = dat,ids = c("country","airport"),variable_name = "community")
dat_new2 <- dat_new %>% group_by(country,`community`) %>%
summarise(`Mean Membership` = mean(value))
# produce Figure 3 for the airports:
g1 <- ggplot(dat_new2, aes( x=country,fill=`community`,y=`Mean Membership`)) +
geom_bar(position="stack", stat="identity") +
ggtitle("Mean Community Membership: Airports")
png("../output/worldwide_flights_1.png",units='in',width=5,height=5,res=300)
g1
dev.off()
dt <- as.data.frame(clusts[[1]][[1]])
dt$country <- "Other"
dt$country[which(rownames(clusts[[1]][[1]]) %in%
select_airl_info[select_airl_info$V7 ==
'United States',]$V2)] <- "USA"
dt$country[which(rownames(clusts[[1]][[1]]) %in%
select_airl_info[select_airl_info$V7 ==
'China',]$V2)] <- "China"
dt$airline <- rownames(clusts[[1]][[1]])
dt <- melt(dt,ids=c("country","airline"),variable_name = 'community')
dt2 <- dt %>% group_by(country,`community`) %>%
summarise(`Mean Membership` = mean(value))
# produce figure 3 for the airlines (right)
g2 <- ggplot(dt2, aes( x=country,fill=`community`,y=`Mean Membership`)) +
geom_bar(position="stack", stat="identity") +
ggtitle("Mean Community Membership: Airlines")
png("../output/worldwide_flights_2.png",units='in',width=5,height=5,res=300)
g2
dev.off()
################################
# Additional Analysis for the airlines (not in paper)
################################
#united airlines community (whose membership is >.5)
clus1 <- pick_linename[which(clusts[[1]][[1]][,1] > .5)]
select_airl_info[select_airl_info$V4 %in% clus1,]$V2
#second airline is US airways
clus2 <- pick_linename[which(clusts[[1]][[1]][,2] > .5)]
select_airl_info[select_airl_info$V4 %in% clus2,]$V2
#third is british airways
clus3 <- pick_linename[which(clusts[[1]][[1]][,3] > .5)]
select_airl_info[select_airl_info$V4 %in% clus3,]$V2
#fourth is delta
clus4 <- pick_linename[which(clusts[[1]][[1]][,4] > .5)]
select_airl_info[select_airl_info$V4 %in% clus4,]$V2
#fifth is air china
clus5 <- pick_linename[which(clusts[[1]][[1]][,5] > .5)]
select_airl_info[select_airl_info$V4 %in% clus5,]$V2
clusts[[1]][[1]][which(rownames(clusts[[1]][[1]]) %in% select_airl_info[select_airl_info$V4 %in% clus5,]$V2),]
#first cluster mostly corresponds to london
ports1 <- pick_portname[which(clusts[[1]][[2]][,1] > .5)]
select_airport_info[select_airport_info$V5 %in% ports1,]$V2
#second cluster corresponds primarily to high-degree or Atlanta
ports2 <- pick_portname[which(clusts[[1]][[2]][,2] > .5)]
select_airport_info[select_airport_info$V5 %in% ports2,]$V2
#third cluster corresponds primarily to USA, but contains many airports
ports3 <- pick_portname[which(clusts[[1]][[2]][,3] > .5)]
select_airport_info[select_airport_info$V5 %in% ports3,]$V2
#fourth airport cluster corresponds to PEK which is Beijing.
ports4 <- pick_portname[which(clusts[[1]][[2]][,4] > .5)]
select_airport_info[select_airport_info$V5 %in% ports4,]$V2
#fifth cluster is basically just miscellaneous
ports5 <- pick_portname[which(clusts[[1]][[2]][,5] > .9)]
select_airport_info[select_airport_info$V5 %in% ports5,]$V2
source("misc.R")
source("HOOI.R")
source("membership_estimation.R")
source("estimate_rank.R")
source("pltfunctions.R")
library(airportr)
require(geonames)
require(maps)
library(ggplot2)
#first produce the network as a tensor
load("US_airport_networks-only48states.RData")
#first produce the network as a tensor
load("../data/US_airport_networks-only48states.RData")
air_tensor <- array(0,c(69,343,343))
for (i in c(1:length(Adj_list_new))) {
air_tensor[i,,] <- as.matrix(Adj_list_new[[i]])
}
air_tensor <- as.tensor(air_tensor)
# we now edit the names slightly for formatting using airport_lookup
airport_names <- rep("",length(lcc))
for (i in 1:length(lcc)) {
if (i == 285) {
airport_names[i] <- "Grant County"
} else {
airport_names[i] <- airport_lookup(lcc[i],output_type="city")
}
}
# select 1st dimension
#first try to embed by deleting the diagonal:
mat1 <- k_unfold(air_tensor,1)@data
toembed <- mat1 %*% t(mat1)
diag(toembed) <- 0
embed1 <- eigen(toembed)
togetelbows <- embed1$values[embed1$values >= 0]
togetelbows #only 2 positive values
r1 <- getElbows(togetelbows)
r1 #results in only two positive eigenvalues.
#try again using vanilla svd scree plot
mat1 <- k_unfold(air_tensor,1)@data
embed1 <-svd(mat1)
togetelbows <- embed1$d# embed1$values[embed1$values >= 0]
r1 <- getElbows(togetelbows)
r1 #1 4 18
#don't want to choose 1, so choose 4 for interpretability
r1 <- r1[2]
#get second embedding dimension
mat2 <- k_unfold(air_tensor,2)@data
toembed <- mat2 %*% t(mat2)
diag(toembed) <- 0
embed1 <- eigen(toembed)
togetelbows <- embed1$values[embed1$values >= 0]
togetelbows <- sqrt(togetelbows)#only look at postitive
r2 <- getElbows(togetelbows)
r2 #1 3 9
r2 <- r2[2] #keep r2 = 3
# by symmetry we set the third mode to have the same rank as the second
rs <- c(r1,r2,r2)
#find embedding and estimate memberships
Uhats <- HOOI_dd(air_tensor,r= rs, niter=20)
clusts <- SPAMM(uhats = Uhats,threshold=T,tval=10^(-20))
#process data for plotting
rownames(clusts[[1]][[2]]) <- lcc
dat <- as.data.frame(clusts[[1]][[2]])
names(dat) <- paste("Pure_node",lcc[clusts[[2]][[2]]],sep="_")
dat$airport <- airport_names
dat$airport2 <- lcc
# we will load the latitude and longitude data for plotting
cities <- read.csv("uscities.csv")
# we will load the latitude and longitude data for plotting
cities <- read.csv("../data/uscities.csv")
latitude <- rep(0,nrow(dat))
longitude <- rep(0,nrow(dat))
for (i in c(1:length(latitude))) {
if(any(cities$city == dat$airport[i])) {
latitude[i] <- cities[which(cities$city == dat$airport[i])[1],"lat"]
longitude[i] <- cities[which(cities$city == dat$airport[i])[1],"lng"]
# a few don't work so we do it manually:
} else if (dat$airport[i] == "Dallas-Fort Worth") {
latitude[i] <- cities[which(cities$city == "Dallas")[1],"lat"]
longitude[i] <- cities[which(cities$city == "Dallas")[1],"lng"]
} else if (dat$airport[i] == "Sault Ste Marie" ) {
latitude[i] <- 46.5136
longitude[i] <- 84.3476
} else if (dat$airport[i] == "Wassau") {
latitude[i] <- 44.9591
longitude[i] <- 89.6301
} else if (dat$airport[i] == "Montrose CO") {
latitude[i] <- 38.4783
longitude[i] <-  107.8762
} else if (dat$airport[i] ==   "Windsor Locks" ) {
latitude[i] <-41.9243
longitude[i] <-  72.6454
} else if (dat$airport[i] ==  "Manchester NH" ) {
latitude[i] <-42.9956
longitude[i] <-  71.4548
} else if (dat$airport[i] ==  "Raleigh-durham"  ) {
latitude[i] <- 35.8992
longitude[i] <-  78.8636
} else if (dat$airport[i] ==  "Charlottesville VA" ) {
latitude[i] <-38.0293
longitude[i] <- 78.4767
} else if (dat$airport[i] ==  "Lexington KY") {
latitude[i] <-38.0406
longitude[i] <-  84.5037
} else if (dat$airport[i] ==  "Roanoke VA" ) {
latitude[i] <-37.2710
longitude[i] <-  79.9414
} else if (dat$airport[i] ==  "BRISTOL") {
latitude[i] <-36.5951
longitude[i] <-  82.1887
} else if (dat$airport[i] ==  "Jacksn Hole" ) {
latitude[i] <-43.4799
longitude[i] <-  110.7624
} else if (dat$airport[i] ==  "Bush Field"  ) {
latitude[i] <-33.3700
longitude[i] <-  81.9652
} else if (dat$airport[i] ==  "Islip"  ) {
latitude[i] <-40.7298
longitude[i] <-  73.2104
} else if (dat$airport[i] ==  "Mcallen") {
latitude[i] <-26.2034
longitude[i] <-  98.2300
} else if (dat$airport[i] ==  "Jacksonville NC" ) {
latitude[i] <-30.3322
longitude[i] <-  81.6557
} else if (dat$airport[i] ==  "State College Pennsylvania") {
latitude[i] <-40.7934
longitude[i] <-  77.8600
} else if (dat$airport[i] ==  "Redmond-Bend" ) {
latitude[i] <-44.2726
longitude[i] <- 121.1739
} else if (dat$airport[i] ==  "MONTGOMERY" ) {
latitude[i] <-32.3792
longitude[i] <-  86.3077
} else if (dat$airport[i] ==  "Hattiesburg/Laurel"  ) {
latitude[i] <-31.4682
longitude[i] <-  89.3354
} else if (dat$airport[i] ==  "Arcata CA" ) {
latitude[i] <-40.8665
longitude[i] <- 124.0828
} else if (dat$airport[i] ==   "Vineyard Haven MA" ) {
latitude[i] <-41.4543
longitude[i] <-  70.6036
} else if (dat$airport[i] ==  "Barnstable") {
latitude[i] <-41.7003
longitude[i] <-  70.3002
} else if (dat$airport[i] ==  "PARKERSBURG"  ) {
latitude[i] <-39.2667
longitude[i] <-  81.5615
} else if (dat$airport[i] ==  "Devils Lake" ) {
latitude[i] <-48.1128
longitude[i] <-  98.8651
} else if (dat$airport[i] ==  "Grant County") {
latitude[i] <-40.4731
longitude[i] <-  85.6846
} else if (dat$airport[i] ==  "Riverton WY" ) {
latitude[i] <-43.0247
longitude[i] <-  108.3806
} else if (dat$airport[i] ==  "Nantucket" ) {
latitude[i] <-41.2835
longitude[i] <-  70.0995
} else if (dat$airport[i] ==  "PADUCAH"  ) {
latitude[i] <-37.0834
longitude[i] <-  88.6000
} else if (dat$airport[i] ==  "Columbus Mississippi" ) {
latitude[i] <-33.4957
longitude[i] <-  88.4273
} else if (dat$airport[i] ==  "Bar Harbor"  ) {
latitude[i] <-44.3876
longitude[i] <-  68.2039
} else {
latitude[i] <- NA
longitude[i] <- NA
}
}
dat$LAT <- latitude
dat$LON <- -abs(longitude)
dat[which(is.na(dat$lat)),"airport"]
purenode_airports <- lcc[clusts[[2]][[2]]]
purenode_airports2 <- airport_names[clusts[[2]][[2]]]
dat$purenode1 <- ifelse(dat$airport2 %in% purenode_airports,40,20)
dat$purenode2 <- as.factor(ifelse(dat$airport2 %in% purenode_airports,"100","0"))
purenode_airports2 # list of pure nodes
# Draw maps of airports (figure 5)
gs <- list() # list of plots
# for each pure node, we plot the memberships and manually format for the paper
for (i in c(1:length(purenode_airports))) {
gs[[i]] <- make_US_plot(dat,purenode_airports[i]) #calls from the pltfunctions.R script
flnme <- paste0("pure_node_",purenode_airports[i],".png")
png(flnme,units='in',width=5,height=5,res=300)
print(gs[[i]])
dev.off()
}
# for each pure node, we plot the memberships and manually format for the paper
for (i in c(1:length(purenode_airports))) {
gs[[i]] <- make_US_plot(dat,purenode_airports[i]) #calls from the pltfunctions.R script
flnme <- paste0("../output/pure_node_",purenode_airports[i],".png")
png(flnme,units='in',width=5,height=5,res=300)
print(gs[[i]])
dev.off()
}
gs[[1]]
gs[[2]]
gs[[3]]
# Draw time plots (figure 4)
start_v <- as.Date("2016-01-01")
dtvals <- seq.Date(from = start_v, length.out = 69, by = "month")
plts <- list()
# for each pure node we make a smoothed plot
for ( i in c(1:rs[1])) {
dt <- dtvals[clusts[[2]][[1]][i]]
plts[[i]] <- make_time_plot(i,tt= paste0("Pure Node:",dt)) #uses pltfunctions.R
flnme <- paste0("../output/pure_node_",dt,".png")
png(flnme,units='in',width=5,height=5,res=300)
print(plts[[i]])
dev.off()
}
# we also make figure 6 by combining pure nodes
png("janmarch.png",units='in',width=5,height=5,res=300)
dev.off()
# we also make figure 6 by combining pure nodes
png("../output/janmarch.png",units='in',width=5,height=5,res=300)
make_time_plot(c(1,3),combine=T,tt="January 2021 and March 2020")
dev.off()
png("../output/janaug.png",units='in',width=5,height=5,res=300)
make_time_plot(c(1,2),combine=T,tt="January 2021 and August 2021")
dev.off()
plts[[1]]
plts[[2]]
plts[[3]]
plts[[4]]
plts[[5]]
pltclust(5)
